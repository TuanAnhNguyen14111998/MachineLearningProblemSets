{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of Weekly-Project-BBC Articles.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8btHNo7H5Cf",
        "colab_type": "text"
      },
      "source": [
        "# Organize ML projects with Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yK9CuWlH5Ch",
        "colab_type": "text"
      },
      "source": [
        "While Machine Learning is powerful, people often overestimate it: apply machine learning to your project, and all your problems will be solved. In reality, it's not this simple. To be effective, one needs to organize the work very well. In this notebook, we will walkthrough practical aspects of a ML project. To look at the big picture, let's start with a checklist below. It should work reasonably well for most ML projects, but make sure to adapt it to your needs:\n",
        "\n",
        "1. **Define the scope of work and objective**\n",
        "    * How is your solution be used?\n",
        "    * How should performance be measured? Are there any contraints?\n",
        "    * How would the problem be solved manually?\n",
        "    * List the available assumptions, and verify if possible.\n",
        "    \n",
        "    \n",
        "2. **Get the data**\n",
        "    * Document where you can get that data\n",
        "    * Store data in a workspace you can easily access\n",
        "    * Convert the data to a format you can easily manipulate\n",
        "    * Check the overview (size, type, sample, description, statistics)\n",
        "    * Data cleaning\n",
        "    \n",
        "    \n",
        "3. **EDA & Data transformation**\n",
        "    * Study each attribute and its characteristics (missing values, type of distribution, usefulness)\n",
        "    * Visualize the data\n",
        "    * Study the correlations between attributes\n",
        "    * Feature selection, Feature Engineering, Feature scaling\n",
        "    * Write functions for all data transformations\n",
        "    \n",
        "    \n",
        "4. **Train models**\n",
        "    * Automate as much as possible\n",
        "    * Train promising models quickly using standard parameters. Measure and compare their performance\n",
        "    * Analyze the errors the models make\n",
        "    * Shortlist the top three of five most promising models, preferring models that make different types of errors.\n",
        "\n",
        "\n",
        "5. **Fine-tunning**\n",
        "    * Treat data transformation choices as hyperparameters, expecially when you are not sure about them (e.g., replace missing values with zeros or with the median value)\n",
        "    * Unless there are very few hyperparameter value to explore, prefer random search over grid search.\n",
        "    * Try ensemble methods\n",
        "    * Test your final model on the test set to estimate the generalizaiton error. Don't tweak your model again, you would start overfitting the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofeuKevOH5Ch",
        "colab_type": "text"
      },
      "source": [
        "## Example: Articles categorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2NSUqUEH5Ci",
        "colab_type": "text"
      },
      "source": [
        "### Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GttlMG-H5Cj",
        "colab_type": "text"
      },
      "source": [
        "Build a model to determine the categories of articles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwbjWOG1H5Ck",
        "colab_type": "text"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWq7xex_H5Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9W7Hzt2H5Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbc = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/bbc-text.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teb1QvD1H5Cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7fe03e84-7688-4571-a15d-bf1b9b321952"
      },
      "source": [
        "bbc.sample(5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>business</td>\n",
              "      <td>putin backs state grab for yukos russia s pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>sport</td>\n",
              "      <td>parker misses england clash tom shanklin will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>business</td>\n",
              "      <td>industrial revival hope for japan japanese ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>george michael to perform for bbc george micha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>business</td>\n",
              "      <td>huge rush for jet airways shares indian airlin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           category                                               text\n",
              "497        business  putin backs state grab for yukos russia s pres...\n",
              "789           sport  parker misses england clash tom shanklin will ...\n",
              "391        business  industrial revival hope for japan japanese ind...\n",
              "2064  entertainment  george michael to perform for bbc george micha...\n",
              "1949       business  huge rush for jet airways shares indian airlin..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBW_Sg2RH5Cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "035f5abd-657d-4e68-e44b-15e696aa9c5a"
      },
      "source": [
        "bbc.info()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3VRY5Zxmw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3595fa45-3595-4d98-ed0f-7007dbd8ad31"
      },
      "source": [
        "# Your code here\n",
        "bbc.describe()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2225</td>\n",
              "      <td>2225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5</td>\n",
              "      <td>2126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>sport</td>\n",
              "      <td>britons fed up with net service a survey condu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>511</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       category                                               text\n",
              "count      2225                                               2225\n",
              "unique        5                                               2126\n",
              "top       sport  britons fed up with net service a survey condu...\n",
              "freq        511                                                  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBEQ9Wo5nYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cfa3d181-bca9-49aa-cc85-ae532cba599a"
      },
      "source": [
        "bbc['category'].value_counts()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mesn5lFE5pYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3c862df-e86f-4320-97f7-a03686b422fc"
      },
      "source": [
        "bbc.columns"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['category', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQVqCQjO5wxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(bbc[\"text\"], bbc[\"category\"], test_size=0.2)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXZMZIZ25-no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe1b7d05-1dfc-4102-fa84-cd3bc60dec09"
      },
      "source": [
        "text_tokenizer = Tokenizer(num_words = 10000, oov_token=\"<OOV>\")\n",
        "text_tokenizer.fit_on_texts(np.array(x_train))\n",
        "text_word_index = text_tokenizer.word_index\n",
        "text_sequences = text_tokenizer.texts_to_sequences(np.array(x_train))\n",
        "padded_text_sequences = pad_sequences(text_sequences, padding='post', maxlen=150)\n",
        "\n",
        "category_tokenizer = Tokenizer()\n",
        "category_tokenizer.fit_on_texts(np.array(y_train))\n",
        "category_word_index = category_tokenizer.word_index\n",
        "category_sequences = np.array(category_tokenizer.texts_to_sequences(np.array(y_train)))\n",
        "category_sequences.reshape(category_sequences.shape[0],)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, ..., 3, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvxS7x1e6K4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "db1df4c0-b9e8-4952-92f8-42cae66bdd46"
      },
      "source": [
        "validation_text_sequences = text_tokenizer.texts_to_sequences(np.array(x_test))\n",
        "validation_text_padded = pad_sequences(validation_text_sequences, padding='post', maxlen=150)\n",
        "\n",
        "validation_category_sequences = np.array(category_tokenizer.texts_to_sequences(np.array(y_test)))\n",
        "validation_category_sequences.reshape(validation_category_sequences.shape[0],)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 3, 3, 4, 5, 3, 1, 2, 4, 1, 1, 1, 3, 5, 2, 2, 3, 2, 1, 2, 1,\n",
              "       3, 2, 2, 4, 4, 3, 1, 2, 4, 5, 3, 1, 3, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
              "       4, 4, 4, 5, 2, 2, 1, 2, 5, 2, 5, 4, 4, 2, 5, 2, 3, 4, 1, 2, 3, 1,\n",
              "       5, 2, 3, 2, 5, 2, 3, 3, 5, 1, 1, 5, 3, 4, 5, 1, 1, 2, 2, 3, 4, 4,\n",
              "       4, 2, 2, 3, 5, 1, 3, 5, 3, 2, 2, 1, 5, 1, 3, 1, 5, 2, 3, 2, 1, 2,\n",
              "       4, 4, 5, 3, 1, 5, 4, 1, 4, 2, 1, 5, 3, 2, 1, 1, 4, 2, 5, 1, 5, 5,\n",
              "       5, 5, 2, 3, 2, 3, 5, 2, 1, 1, 1, 1, 5, 2, 3, 2, 2, 4, 5, 5, 4, 1,\n",
              "       2, 4, 5, 4, 3, 3, 2, 1, 3, 3, 5, 5, 5, 5, 4, 1, 3, 1, 2, 3, 2, 1,\n",
              "       1, 2, 4, 2, 4, 2, 5, 3, 5, 2, 3, 3, 3, 1, 1, 5, 3, 5, 2, 4, 5, 4,\n",
              "       3, 4, 3, 3, 5, 4, 2, 3, 2, 3, 4, 5, 1, 1, 2, 3, 3, 2, 2, 5, 4, 5,\n",
              "       2, 3, 5, 5, 2, 4, 3, 3, 2, 3, 2, 4, 1, 1, 2, 5, 1, 3, 4, 4, 2, 3,\n",
              "       5, 2, 2, 3, 4, 2, 2, 2, 5, 3, 3, 1, 3, 2, 1, 4, 3, 5, 4, 1, 5, 3,\n",
              "       3, 1, 3, 4, 1, 5, 2, 5, 4, 3, 5, 1, 4, 3, 4, 4, 4, 2, 1, 3, 4, 1,\n",
              "       1, 4, 3, 1, 5, 2, 2, 3, 1, 2, 2, 1, 2, 2, 3, 1, 4, 1, 1, 3, 1, 5,\n",
              "       3, 1, 5, 5, 1, 4, 3, 2, 1, 4, 1, 2, 2, 3, 2, 2, 4, 3, 1, 2, 1, 3,\n",
              "       1, 4, 2, 1, 3, 5, 3, 1, 2, 4, 1, 5, 1, 5, 1, 4, 1, 4, 1, 1, 4, 2,\n",
              "       1, 3, 2, 4, 1, 1, 4, 4, 5, 1, 2, 1, 1, 3, 5, 1, 3, 4, 5, 1, 3, 4,\n",
              "       1, 5, 1, 5, 1, 3, 5, 3, 2, 3, 1, 5, 4, 4, 4, 3, 3, 2, 1, 1, 3, 2,\n",
              "       2, 2, 2, 3, 2, 3, 5, 1, 4, 3, 2, 5, 1, 2, 3, 4, 1, 1, 1, 2, 2, 1,\n",
              "       2, 4, 2, 5, 4, 2, 4, 5, 2, 3, 2, 3, 4, 1, 2, 4, 4, 3, 4, 1, 2, 3,\n",
              "       4, 2, 5, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3jogqix75KZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "675ed507-65fc-4fb8-81ce-f3ba5596810f"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(10000, 200, input_length=150),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 200)          2000000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                4824      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 150       \n",
            "=================================================================\n",
            "Total params: 2,004,974\n",
            "Trainable params: 2,004,974\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rxBz-jg78Th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "d6f9f473-78ba-48bd-eced-35c4006341eb"
      },
      "source": [
        "history = model.fit(padded_text_sequences, category_sequences, epochs=20, validation_data=(validation_text_padded, validation_category_sequences), verbose=2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "56/56 - 2s - loss: 1.6857 - accuracy: 0.5129 - val_loss: 1.5255 - val_accuracy: 0.4944\n",
            "Epoch 2/20\n",
            "56/56 - 1s - loss: 1.2929 - accuracy: 0.6129 - val_loss: 1.0652 - val_accuracy: 0.7258\n",
            "Epoch 3/20\n",
            "56/56 - 1s - loss: 0.8060 - accuracy: 0.8674 - val_loss: 0.6698 - val_accuracy: 0.9124\n",
            "Epoch 4/20\n",
            "56/56 - 1s - loss: 0.4447 - accuracy: 0.9545 - val_loss: 0.4318 - val_accuracy: 0.9393\n",
            "Epoch 5/20\n",
            "56/56 - 1s - loss: 0.2412 - accuracy: 0.9798 - val_loss: 0.3121 - val_accuracy: 0.9461\n",
            "Epoch 6/20\n",
            "56/56 - 1s - loss: 0.1377 - accuracy: 0.9893 - val_loss: 0.2493 - val_accuracy: 0.9393\n",
            "Epoch 7/20\n",
            "56/56 - 1s - loss: 0.0836 - accuracy: 0.9961 - val_loss: 0.2174 - val_accuracy: 0.9438\n",
            "Epoch 8/20\n",
            "56/56 - 1s - loss: 0.0531 - accuracy: 0.9989 - val_loss: 0.1956 - val_accuracy: 0.9461\n",
            "Epoch 9/20\n",
            "56/56 - 1s - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9483\n",
            "Epoch 10/20\n",
            "56/56 - 2s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9461\n",
            "Epoch 11/20\n",
            "56/56 - 1s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9461\n",
            "Epoch 12/20\n",
            "56/56 - 1s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9483\n",
            "Epoch 13/20\n",
            "56/56 - 1s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9483\n",
            "Epoch 14/20\n",
            "56/56 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9483\n",
            "Epoch 15/20\n",
            "56/56 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9483\n",
            "Epoch 16/20\n",
            "56/56 - 1s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9483\n",
            "Epoch 17/20\n",
            "56/56 - 1s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9483\n",
            "Epoch 18/20\n",
            "56/56 - 1s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9483\n",
            "Epoch 19/20\n",
            "56/56 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9483\n",
            "Epoch 20/20\n",
            "56/56 - 1s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMyuy35w_YDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "09552719-54fd-460d-a136-fb768658d1e4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "predictions = model.predict(validation_text_padded)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "print('accuracy:',accuracy_score(validation_category_sequences,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(validation_category_sequences,predictions))\n",
        "print('classification report:\\n',classification_report(validation_category_sequences,predictions))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9483146067415731\n",
            "confusion matrix:\n",
            " [[ 99   0   0   0   0]\n",
            " [  1 102   2   1   2]\n",
            " [  1   3  82   2   2]\n",
            " [  0   0   2  71   3]\n",
            " [  0   1   1   2  68]]\n",
            "classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      1.00      0.99        99\n",
            "           2       0.96      0.94      0.95       108\n",
            "           3       0.94      0.91      0.93        90\n",
            "           4       0.93      0.93      0.93        76\n",
            "           5       0.91      0.94      0.93        72\n",
            "\n",
            "    accuracy                           0.95       445\n",
            "   macro avg       0.95      0.95      0.95       445\n",
            "weighted avg       0.95      0.95      0.95       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ZCyJghBBFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}